model_entity: nomic-ai
model_name: nomic-embed-text-v1
model_name_or_path: ${model_entity}/${model_name}
output_dir: ../checkpoints/rag-replay/${model_name}

wandb_init:
  job_type: "train-rag"
  tags: ["${model_name}", "RAG"]


input_artifact_version: "v2"
file_name_answers: "openai-answers-${input_artifact_version}.parquet"
input_artifact_answers:
  artifact_or_name: "openai-answers-${input_artifact_version}:latest"
  type: "openai-synthetic"


file_name_knowledge: "openai-knowledge-${input_artifact_version}.parquet"
input_artifact_knowledge:
  artifact_or_name: "openai-knowledge-${input_artifact_version}:latest"
  type: "openai-synthetic"

output_artifact:
  name: "replay-rag-${model_name}"
  type: replay-rag
  metadata: 
    model_name: ${model_name}


trainer:
    # Required parameter:
    output_dir: ${output_dir}
    # Optional training parameters:
    num_train_epochs: 2
    per_device_train_batch_size: 4
    per_device_eval_batch_size: 4
    learning_rate: 1e-4
    warmup_ratio: 0.1
    fp16: False  # Set to False if you get an error that your GPU can't run on FP16
    bf16: True  # Set to True if you have a GPU that supports BF16
    batch_sampler: no_duplicates  # losses that use "in-batch negatives" benefit from no duplicates
    gradient_accumulation_steps: 4
    # Optional tracking/debugging parameters:
    eval_strategy: "steps"
    eval_steps: 500
    save_strategy: "steps"
    save_steps: 500
    save_total_limit: 2
    logging_steps: 100